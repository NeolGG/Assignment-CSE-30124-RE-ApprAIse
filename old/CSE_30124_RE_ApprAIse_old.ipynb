{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nslKz_e-LT16"
      },
      "source": [
        "## Import data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5k8eUDaN68-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from joblib import dump,load\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cLAoVzCQOPc"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('usa_housing.csv'):\n",
        "    !wget \"https://drive.usercontent.google.com/download?id=1fqh567slCa7vPhHGIQ1g7szImts_71mx&export=download&authuser=0&confirm=t&uuid=ba0d436c-a9f8-4c30-9571-54437683395b&at=APZUnTWagNdHJ7SK1BxfNQpSmOpr:1700065030553\" -O 'usa_housing.csv'\n",
        "\n",
        "df = pd.read_csv('usa_housing.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jZ_rg83QpwK"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxpRgby1Rjtp"
      },
      "outputs": [],
      "source": [
        "print(df.info())\n",
        "\n",
        "#we have A LOT of null values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY2ObHrORlmK"
      },
      "source": [
        "## Clean up lines and remove useless columns\n",
        "\n",
        "I cleaned up this data by removing all rows with null values and also remove the following columns:\n",
        "\n",
        "  zip_code, status, city\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGaT4nJnUOn3"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True) #remove NaN vlaues\n",
        "\n",
        "columns_to_remove = ['status','zip_code','city'] #useless columns\n",
        "\n",
        "df.drop(columns_to_remove,inplace=True,axis=1) #drops the useless columns\n",
        "\n",
        "df = df.reset_index(drop=True) #fixes the indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osm-FUdGKCA0"
      },
      "outputs": [],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHgu_nHiFMDU"
      },
      "source": [
        "## Convert to date to year only and include years after 2010"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aHRgQQvUpdc"
      },
      "outputs": [],
      "source": [
        "df['prev_sold_date'] = df['prev_sold_date'].astype(str).str[:4]\n",
        "\n",
        "df['prev_sold_date'] = pd.to_numeric(df['prev_sold_date'])\n",
        "\n",
        "df = df[df['prev_sold_date'] >= 2010]\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "word_counts = Counter(df['state'])\n",
        "\n",
        "word_counts_dict = dict(word_counts)\n",
        "\n",
        "print(word_counts_dict)\n",
        "print(len(word_counts_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGCTk9tTJEya"
      },
      "source": [
        "## Remove prev_sold_date column\n",
        "\n",
        "The year column is being removed since all data is now after 2010, which is after the 2008 crash, so it's safe to assume the prices are reasonable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFNn4OxDJGxp"
      },
      "outputs": [],
      "source": [
        "df.drop(['prev_sold_date'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9O1vj69Jbz0"
      },
      "outputs": [],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxfw4DGEKGO"
      },
      "source": [
        "## Remove least occuring states\n",
        "\n",
        "Since Puerto Rico and Virgin Islands only have 6 we remove them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6itu1FfqENlp"
      },
      "outputs": [],
      "source": [
        "states_to_delete = ['Puerto Rico','Virgin Islands'] # have only 20 and 6 listings\n",
        "\n",
        "df = df[~df['state'].isin(states_to_delete)]\n",
        "df = df.reset_index(drop=True) #fixes the indexes\n",
        "\n",
        "word_counts = Counter(df['state'])\n",
        "\n",
        "word_counts_dict = dict(word_counts)\n",
        "\n",
        "print(word_counts_dict)\n",
        "print(len(word_counts_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zryxkIX8LY8u"
      },
      "source": [
        "## Method 1: Label Encode states and remove states column\n",
        "\n",
        "we assign an encode value to each state, create a mapping dictionary, and remove the states column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNQReLZ1HOUV"
      },
      "outputs": [],
      "source": [
        "df2 = df.copy()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['state_encoded'] = label_encoder.fit_transform(df['state'])\n",
        "\n",
        "mapping = dict(zip(df['state'], label_encoder.fit_transform(df['state']))) #mapping dict\n",
        "\n",
        "df.drop(['state'],inplace=True,axis=1)\n",
        "\n",
        "print(mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpr7YR0ARH-d"
      },
      "source": [
        "## Method 2: separate dataset into subsets\n",
        "\n",
        "We separate df2 into subsets based on states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp1ps_3HRHqL"
      },
      "outputs": [],
      "source": [
        "grouped = df2.groupby('state')\n",
        "\n",
        "df_dict = {state: group for state, group in grouped} #dictionary of group data\n",
        "\n",
        "for name,item in df_dict.items():\n",
        "  item.drop(['state'],inplace=True,axis=1)\n",
        "  print(name)\n",
        "  makeModel(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOzsP-PIeTIM"
      },
      "source": [
        "# Housing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhOMJJv2ebKw"
      },
      "outputs": [],
      "source": [
        "def makeModel(dataframe):\n",
        "  X = dataframe.drop(\"price\", axis=1)\n",
        "  y = dataframe[\"price\"]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"R^2 Score: {r2}\")\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMqz7dkfe0-p"
      },
      "source": [
        "## If you want to save the model, use the dump command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUvlVHfDe5te"
      },
      "outputs": [],
      "source": [
        "dump(model, 'kc_housingmodel.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjZcmjR_e9O_"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vktNeQoTfEYZ"
      },
      "outputs": [],
      "source": [
        "# test data - USES METHOD 2 befault\n",
        "\n",
        "USEMETHOD1 = 0\n",
        "\n",
        "bed   =   float(input(\"Enter how many beds: \"))\n",
        "bath  =   float(input(\"Enter how many bathrooms: \"))\n",
        "acres =   float(input(\"Enter how many acres the land is: \"))\n",
        "size  =   float(input(\"Enter how the size of the house in square feet: \"))\n",
        "\n",
        "print(\"Choose one of the following states:\")\n",
        "for state in word_counts_dict.keys():\n",
        "    print(f\"{state}\")\n",
        "\n",
        "state =   input(\"Enter the number of your chosen state: \")\n",
        "\n",
        "if USEMETHOD1:\n",
        "  state = mapping[state]\n",
        "  model = makeModel(df)\n",
        "else:\n",
        "  model = makeModel(df_dict[state])\n",
        "\n",
        "data = {\n",
        "    'bed': [bed],\n",
        "    'bath': [bath],\n",
        "    'acre_lot': [acres],\n",
        "    'house_size': [size],\n",
        "}\n",
        "\n",
        "if USEMETHOD1:\n",
        "  data.update({'state_encoded': [state]})\n",
        "  print(\"Method 1\")\n",
        "else:\n",
        "  print(\"Method 2\")\n",
        "\n",
        "input_df = pd.DataFrame(data)\n",
        "\n",
        "prediction = list(model.predict(input_df))\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Predicted Price:\")\n",
        "print(f\"${prediction[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UebgWlIfVhjy"
      },
      "outputs": [],
      "source": [
        "#Scatter Plot\n",
        "temp = df_dict[state]\n",
        "\n",
        "tempBeds = temp['bed']\n",
        "tempBaths = temp['bath']\n",
        "tempAcres = temp['acre_lot']\n",
        "tempSize = temp['house_size']\n",
        "tempPrice = temp['price']\n",
        "\n",
        "plt.scatter(tempAcres,tempPrice,c='blue',marker='o',label='Collected Data')\n",
        "\n",
        "plt.scatter(acres,prediction,c='red', marker='o', label='Input Point', s=100)\n",
        "\n",
        "plt.xlabel('Acre Lot')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Acre Lot vs. Price')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
